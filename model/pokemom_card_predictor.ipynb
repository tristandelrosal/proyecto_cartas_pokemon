{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pokemon cards predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries\n",
    "Import the necessary libraries, including os, pandas, and any custom functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance, ImageFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Output Directory\n",
    "Use os.makedirs() to create the output directory if it doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up Output Directory\n",
    "output_dir = 'output_images'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Variations for Images\n",
    "Iterate over the DataFrame rows, generate image variations, and save them to the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the input data\n",
    "df = pd.read_csv('cards_with_local_paths.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para generar variaciones de una imagen\n",
    "def generate_variations(image_path, image_id):\n",
    "    variations = []\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Incluir la imagen original\n",
    "    variations.append((image, f\"{image_id}_original\"))\n",
    "    \n",
    "    # 1. Blanco y negro\n",
    "    bw = image.convert(\"L\")\n",
    "    variations.append((bw, f\"{image_id}_bw\"))\n",
    "    \n",
    "    # 2. Desenfoque\n",
    "    blurred = image.filter(ImageFilter.GaussianBlur(2))\n",
    "    variations.append((blurred, f\"{image_id}_blurred\"))\n",
    "    \n",
    "    # 3. Más saturación\n",
    "    enhancer = ImageEnhance.Color(image)\n",
    "    saturated = enhancer.enhance(1.5)\n",
    "    variations.append((saturated, f\"{image_id}_saturated\"))\n",
    "    \n",
    "    # 4. Menos saturación\n",
    "    desaturated = enhancer.enhance(0.5)\n",
    "    variations.append((desaturated, f\"{image_id}_desaturated\"))\n",
    "    \n",
    "    # 5. Inclinada a la izquierda\n",
    "    rotated_left = image.rotate(15)\n",
    "    variations.append((rotated_left, f\"{image_id}_rotated_left\"))\n",
    "    \n",
    "    # 6. Inclinada a la derecha\n",
    "    rotated_right = image.rotate(-15)\n",
    "    variations.append((rotated_right, f\"{image_id}_rotated_right\"))\n",
    "    \n",
    "    # 7. Zoom in\n",
    "    zoom_in = image.resize((int(image.width * 1.2), int(image.height * 1.2)))\n",
    "    variations.append((zoom_in, f\"{image_id}_zoom_in\"))\n",
    "    \n",
    "    # 8. Zoom out\n",
    "    zoom_out = image.resize((int(image.width * 0.8), int(image.height * 0.8)))\n",
    "    variations.append((zoom_out, f\"{image_id}_zoom_out\"))\n",
    "    \n",
    "    # 9. Con ruido\n",
    "    noise = image.copy()\n",
    "    noise = noise.convert(\"RGB\")\n",
    "    pixels = noise.load()\n",
    "    for i in range(noise.size[0]):\n",
    "        for j in range(noise.size[1]):\n",
    "            r, g, b = pixels[i, j]\n",
    "            noise_factor = 25\n",
    "            r = int(r + noise_factor * (0.5 - os.urandom(1)[0] / 255))\n",
    "            g = int(g + noise_factor * (0.5 - os.urandom(1)[0] / 255))\n",
    "            b = int(b + noise_factor * (0.5 - os.urandom(1)[0] / 255))\n",
    "            pixels[i, j] = (r, g, b)\n",
    "    variations.append((noise, f\"{image_id}_noise\"))\n",
    "    \n",
    "    # 10. Brillo aumentado\n",
    "    enhancer = ImageEnhance.Brightness(image)\n",
    "    bright = enhancer.enhance(1.5)\n",
    "    variations.append((bright, f\"{image_id}_bright\"))\n",
    "    \n",
    "    # 11. Rotación aleatoria\n",
    "    random_rotation = image.rotate(np.random.uniform(-30, 30))\n",
    "    variations.append((random_rotation, f\"{image_id}_random_rotation\"))\n",
    "    \n",
    "    # 12. Traslación\n",
    "    translated = image.transform(image.size, Image.AFFINE, (1, 0, 10, 0, 1, 10))\n",
    "    variations.append((translated, f\"{image_id}_translated\"))\n",
    "    \n",
    "    # 13. Corte (Crop)\n",
    "    width, height = image.size\n",
    "    crop_area = (10, 10, width - 10, height - 10)\n",
    "    cropped = image.crop(crop_area)\n",
    "    variations.append((cropped, f\"{image_id}_cropped\"))\n",
    "    \n",
    "    # 14. Espejo horizontal\n",
    "    flipped_horizontal = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    variations.append((flipped_horizontal, f\"{image_id}_flipped_horizontal\"))\n",
    "    \n",
    "    # 15. Contraste aumentado\n",
    "    enhancer = ImageEnhance.Contrast(image)\n",
    "    high_contrast = enhancer.enhance(1.5)\n",
    "    variations.append((high_contrast, f\"{image_id}_high_contrast\"))\n",
    "    \n",
    "    return variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Variations for Images\n",
    "variations_data = []\n",
    "\n",
    "for index, row in df.head(102).iterrows():\n",
    "    image_path = row['local_image_path']\n",
    "    image_id = row['id']\n",
    "    variations = generate_variations(image_path, image_id)\n",
    "    for var_image, var_name in variations:\n",
    "        var_image_path = os.path.join(output_dir, f\"{var_name}.png\")\n",
    "        var_image.save(var_image_path)\n",
    "        variations_data.append({'id': image_id, 'local_image_path': var_image_path})\n",
    "\n",
    "# Create a DataFrame with the variations\n",
    "variations_df = pd.DataFrame(variations_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "variations_df.to_csv('cards_with_variations.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame with Variations\n",
    "Create a new DataFrame to store the variations data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con las variaciones\n",
    "variations_df = pd.DataFrame(variations_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save DataFrame to CSV\n",
    "Save the DataFrame with variations to a CSV file using to_csv()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame with variations to a CSV file using to_csv()\n",
    "variations_df.to_csv('cards_with_variations.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entranamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 417ms/step - accuracy: 0.0111 - loss: 30.8460 - val_accuracy: 0.0856 - val_loss: 4.3850\n",
      "Epoch 2/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 446ms/step - accuracy: 0.1251 - loss: 4.0239 - val_accuracy: 0.5352 - val_loss: 2.4734\n",
      "Epoch 3/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 456ms/step - accuracy: 0.5134 - loss: 2.1238 - val_accuracy: 0.8471 - val_loss: 0.6389\n",
      "Epoch 4/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 424ms/step - accuracy: 0.7915 - loss: 0.7499 - val_accuracy: 0.9297 - val_loss: 0.3378\n",
      "Epoch 5/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 429ms/step - accuracy: 0.8998 - loss: 0.3866 - val_accuracy: 0.9235 - val_loss: 0.3227\n",
      "Epoch 6/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 420ms/step - accuracy: 0.9195 - loss: 0.3634 - val_accuracy: 0.9174 - val_loss: 0.3510\n",
      "Epoch 7/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 437ms/step - accuracy: 0.9216 - loss: 0.2942 - val_accuracy: 0.9450 - val_loss: 0.2709\n",
      "Epoch 8/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 462ms/step - accuracy: 0.9497 - loss: 0.1869 - val_accuracy: 0.9419 - val_loss: 0.2362\n",
      "Epoch 9/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 425ms/step - accuracy: 0.9627 - loss: 0.1349 - val_accuracy: 0.9480 - val_loss: 0.3015\n",
      "Epoch 10/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 430ms/step - accuracy: 0.9790 - loss: 0.0692 - val_accuracy: 0.9266 - val_loss: 0.3532\n",
      "Epoch 11/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 423ms/step - accuracy: 0.9577 - loss: 0.2029 - val_accuracy: 0.9388 - val_loss: 0.2978\n",
      "Epoch 12/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 433ms/step - accuracy: 0.9684 - loss: 0.1004 - val_accuracy: 0.9480 - val_loss: 0.2633\n",
      "Epoch 13/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 427ms/step - accuracy: 0.9806 - loss: 0.0582 - val_accuracy: 0.9511 - val_loss: 0.2689\n",
      "Epoch 14/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 433ms/step - accuracy: 0.9866 - loss: 0.0511 - val_accuracy: 0.9511 - val_loss: 0.2210\n",
      "Epoch 15/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 413ms/step - accuracy: 0.9861 - loss: 0.0467 - val_accuracy: 0.9419 - val_loss: 0.2620\n",
      "Epoch 16/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 411ms/step - accuracy: 0.9829 - loss: 0.0626 - val_accuracy: 0.9480 - val_loss: 0.2120\n",
      "Epoch 17/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 472ms/step - accuracy: 0.9916 - loss: 0.0273 - val_accuracy: 0.9480 - val_loss: 0.2615\n",
      "Epoch 18/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 449ms/step - accuracy: 0.9863 - loss: 0.0489 - val_accuracy: 0.9572 - val_loss: 0.2190\n",
      "Epoch 19/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 433ms/step - accuracy: 0.9859 - loss: 0.0439 - val_accuracy: 0.9419 - val_loss: 0.2651\n",
      "Epoch 20/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 447ms/step - accuracy: 0.9828 - loss: 0.0486 - val_accuracy: 0.9450 - val_loss: 0.2649\n",
      "Epoch 21/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 428ms/step - accuracy: 0.9868 - loss: 0.0398 - val_accuracy: 0.9358 - val_loss: 0.3516\n",
      "Epoch 22/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 434ms/step - accuracy: 0.9691 - loss: 0.0955 - val_accuracy: 0.9419 - val_loss: 0.2652\n",
      "Epoch 23/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 450ms/step - accuracy: 0.9798 - loss: 0.0828 - val_accuracy: 0.9541 - val_loss: 0.2742\n",
      "Epoch 24/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 479ms/step - accuracy: 0.9882 - loss: 0.0502 - val_accuracy: 0.9327 - val_loss: 0.2925\n",
      "Epoch 25/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 447ms/step - accuracy: 0.9859 - loss: 0.0495 - val_accuracy: 0.9480 - val_loss: 0.2443\n",
      "Epoch 26/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 426ms/step - accuracy: 0.9917 - loss: 0.0290 - val_accuracy: 0.9480 - val_loss: 0.2440\n",
      "Epoch 27/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 444ms/step - accuracy: 0.9816 - loss: 0.0801 - val_accuracy: 0.9388 - val_loss: 0.3033\n",
      "Epoch 28/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 433ms/step - accuracy: 0.9832 - loss: 0.0612 - val_accuracy: 0.9235 - val_loss: 0.3645\n",
      "Epoch 29/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 437ms/step - accuracy: 0.9840 - loss: 0.0689 - val_accuracy: 0.9419 - val_loss: 0.3082\n",
      "Epoch 30/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 433ms/step - accuracy: 0.9841 - loss: 0.0522 - val_accuracy: 0.9450 - val_loss: 0.2942\n",
      "Epoch 31/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 426ms/step - accuracy: 0.9825 - loss: 0.0559 - val_accuracy: 0.9297 - val_loss: 0.2908\n",
      "Epoch 32/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 464ms/step - accuracy: 0.9954 - loss: 0.0249 - val_accuracy: 0.9450 - val_loss: 0.2628\n",
      "Epoch 33/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 420ms/step - accuracy: 0.9973 - loss: 0.0111 - val_accuracy: 0.9450 - val_loss: 0.3347\n",
      "Epoch 34/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 424ms/step - accuracy: 0.9986 - loss: 0.0060 - val_accuracy: 0.9480 - val_loss: 0.2830\n",
      "Epoch 35/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 449ms/step - accuracy: 0.9913 - loss: 0.0378 - val_accuracy: 0.9602 - val_loss: 0.2423\n",
      "Epoch 36/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 427ms/step - accuracy: 0.9925 - loss: 0.0278 - val_accuracy: 0.9480 - val_loss: 0.2507\n",
      "Epoch 37/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 433ms/step - accuracy: 0.9910 - loss: 0.0248 - val_accuracy: 0.9480 - val_loss: 0.2382\n",
      "Epoch 38/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 458ms/step - accuracy: 0.9861 - loss: 0.0739 - val_accuracy: 0.9419 - val_loss: 0.2603\n",
      "Epoch 39/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 464ms/step - accuracy: 0.9895 - loss: 0.0343 - val_accuracy: 0.9450 - val_loss: 0.2968\n",
      "Epoch 40/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 431ms/step - accuracy: 0.9885 - loss: 0.0368 - val_accuracy: 0.9450 - val_loss: 0.3442\n",
      "Epoch 41/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 431ms/step - accuracy: 0.9839 - loss: 0.0660 - val_accuracy: 0.9358 - val_loss: 0.3632\n",
      "Epoch 42/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 441ms/step - accuracy: 0.9892 - loss: 0.0328 - val_accuracy: 0.9327 - val_loss: 0.3794\n",
      "Epoch 43/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 453ms/step - accuracy: 0.9828 - loss: 0.0814 - val_accuracy: 0.9235 - val_loss: 0.3873\n",
      "Epoch 44/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 440ms/step - accuracy: 0.9882 - loss: 0.0662 - val_accuracy: 0.9388 - val_loss: 0.2762\n",
      "Epoch 45/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 437ms/step - accuracy: 0.9903 - loss: 0.0380 - val_accuracy: 0.9419 - val_loss: 0.3362\n",
      "Epoch 46/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 453ms/step - accuracy: 0.9876 - loss: 0.0483 - val_accuracy: 0.9266 - val_loss: 0.3758\n",
      "Epoch 47/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 461ms/step - accuracy: 0.9908 - loss: 0.0659 - val_accuracy: 0.9358 - val_loss: 0.2857\n",
      "Epoch 48/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 501ms/step - accuracy: 0.9996 - loss: 0.0064 - val_accuracy: 0.9480 - val_loss: 0.2730\n",
      "Epoch 49/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 472ms/step - accuracy: 0.9989 - loss: 0.0058 - val_accuracy: 0.9450 - val_loss: 0.3053\n",
      "Epoch 50/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 447ms/step - accuracy: 0.9972 - loss: 0.0129 - val_accuracy: 0.9511 - val_loss: 0.2796\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9502 - loss: 0.2321\n",
      "Loss: 0.28, Accuracy: 95.11%\n"
     ]
    }
   ],
   "source": [
    "# Leer el dataframe\n",
    "df = pd.read_csv('cards_with_variations.csv')\n",
    "\n",
    "# Preparar los datos\n",
    "image_size = (128, 128)  # Tamaño al que redimensionaremos las imágenes\n",
    "num_classes = df['id'].nunique()  # Número de clases (IDs únicos)\n",
    "\n",
    "# Función para cargar y procesar las imágenes\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')  # Convertir a RGB\n",
    "    image = image.resize(image_size)\n",
    "    image = np.array(image)\n",
    "    return image\n",
    "\n",
    "# Cargar las imágenes y las etiquetas\n",
    "images = np.array([load_image(row['local_image_path']) for _, row in df.iterrows()])\n",
    "labels = to_categorical(df['id'].astype('category').cat.codes, num_classes=num_classes)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Construir el modelo\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(image_size[0], image_size[1], 3)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss:.2f}, Accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo\n",
    "model.save('pokemon_card_predictor.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d.ramirez.vaquero\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 14 variables whereas the saved optimizer has 26 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step\n",
      "Predicted ID: dp1-1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el modelo\n",
    "model = load_model('pokemon_card_predictor.keras')\n",
    "\n",
    "# Función para cargar y procesar una imagen\n",
    "def load_and_preprocess_image(image_path, image_size=(128, 128)):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize(image_size)\n",
    "    image = np.array(image)\n",
    "    if image.shape[-1] == 4:  # Si la imagen tiene un canal alfa, eliminarlo\n",
    "        image = image[..., :3]\n",
    "    image = image / 255.0  # Normalizar la imagen\n",
    "    return image\n",
    "\n",
    "# Función para predecir el ID de una carta\n",
    "def predict_card_id(image_path, model, image_size=(128, 128)):\n",
    "    image = load_and_preprocess_image(image_path, image_size)\n",
    "    image = np.expand_dims(image, axis=0)  # Añadir una dimensión para el batch\n",
    "    predictions = model.predict(image)\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "    return predicted_class[0]\n",
    "\n",
    "# Cargar el DataFrame para obtener el mapeo de IDs\n",
    "df = pd.read_csv('cards_with_variations.csv')\n",
    "id_to_label = {i: label for i, label in enumerate(df['id'].astype('category').cat.categories)}\n",
    "\n",
    "# Probar el modelo con una nueva imagen\n",
    "test_image_path = 'output_images/dp1-1_saturated.png'  # Reemplaza con la ruta de tu imagen de prueba\n",
    "predicted_class = predict_card_id(test_image_path, model)\n",
    "predicted_label = id_to_label[predicted_class]\n",
    "\n",
    "print(f'Predicted ID: {predicted_label}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
